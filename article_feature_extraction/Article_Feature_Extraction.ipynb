{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Article_Feature_Extraction.ipynb\n",
    "---\n",
    "## Objective\n",
    "The goal of **Article Feature Extraction** is to process an Excel file containing a column named `URL` with a list of article links. This process will generate a new Excel file that includes:\n",
    "\n",
    "- **News Source**: Extracted from the URL to identify the originating website.\n",
    "- **Header**: The main headline or title of the article.\n",
    "- **Text**: The cleaned and concatenated body text of the article.\n",
    "- **Authors**: A cleaned list of the article's authors.\n",
    "\n",
    "This cleaned and structured dataset will be prepa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84b98a0753d7e873"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.310842100Z",
     "start_time": "2025-01-13T17:58:46.298841600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def read_excel_file_return_url_dataframe(file):\n",
    "    \"\"\"\n",
    "    Reads an Excel file and returns a DataFrame containing a column of URLs.\n",
    "\n",
    "    Args:\n",
    "        file (str): Path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the data from the Excel file. The file must have a column labeled 'URL'.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the file does not contain a column labeled 'URL'.\n",
    "        Exception: For other file-related errors (e.g., file not found, incorrect format).\n",
    "\n",
    "    Note:\n",
    "        Ensure the Excel file contains a column labeled 'URL' with valid URL values before using this function.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file into a DataFrame\n",
    "        df = pd.read_excel(file)\n",
    "        \n",
    "        # Check if the 'URL' column exists\n",
    "        if 'URL' not in df.columns:\n",
    "            raise ValueError(\"The Excel file must contain a column labeled 'URL'.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame on error\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.350843800Z",
     "start_time": "2025-01-13T17:58:46.306842900Z"
    }
   },
   "id": "1b79fa99f3fdc49a"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "article_df = read_excel_file_return_url_dataframe('URL_Links_Folder/URL_Links.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.351842500Z",
     "start_time": "2025-01-13T17:58:46.321841600Z"
    }
   },
   "id": "abc87bcbe701519f"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def sort_news_sites(article_df):\n",
    "    \"\"\"\n",
    "    Sorts through the list of URL links and extracts the news agency source.\n",
    "\n",
    "    This is important as each website has different HTML structures for their articles,\n",
    "    requiring unique functions to extract features.\n",
    "\n",
    "    Args:\n",
    "        article_df (pd.DataFrame): A DataFrame containing a column 'URL' with article links.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input DataFrame with a new column 'News_Source' containing the extracted news source.\n",
    "    \"\"\"\n",
    "    # Add a new column to store the news source\n",
    "    article_df['News_Source'] = article_df['URL'].apply(\n",
    "        lambda article: re.search(r\"https://www\\.(.*?)\\.com/\", article).group(1) \n",
    "        if re.search(r\"https://www\\.(.*?)\\.com/\", article) else None\n",
    "    )\n",
    "    \n",
    "    return article_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.352845300Z",
     "start_time": "2025-01-13T17:58:46.339842200Z"
    }
   },
   "id": "38a520d1c0acbcb0"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 URL News_Source\n0  https://www.nbcnews.com/politics/politics-news...     nbcnews\n1  https://www.nbcnews.com/news/world/magnitude-6...     nbcnews\n2  https://www.nbcnews.com/news/world/north-korea...     nbcnews\n3  https://www.nbcnews.com/news/world/taliban-not...     nbcnews\n4  https://www.cnn.com/2025/01/13/middleeast/isra...         cnn\n5  https://www.cnn.com/2025/01/13/politics/pete-h...         cnn\n6  https://www.cnn.com/2025/01/11/middleeast/leba...         cnn",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>News_Source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.nbcnews.com/politics/politics-news...</td>\n      <td>nbcnews</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.nbcnews.com/news/world/magnitude-6...</td>\n      <td>nbcnews</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.nbcnews.com/news/world/north-korea...</td>\n      <td>nbcnews</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.nbcnews.com/news/world/taliban-not...</td>\n      <td>nbcnews</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.cnn.com/2025/01/13/middleeast/isra...</td>\n      <td>cnn</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://www.cnn.com/2025/01/13/politics/pete-h...</td>\n      <td>cnn</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://www.cnn.com/2025/01/11/middleeast/leba...</td>\n      <td>cnn</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_news_sites(article_df)\n",
    "article_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.369841500Z",
     "start_time": "2025-01-13T17:58:46.353844100Z"
    }
   },
   "id": "987d017818f0adde"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def extract_article_features_NBC(url_command):\n",
    "    \"\"\"\n",
    "    Extract the header, article body text, and authors from a news article.  Note this function has been created with the specifications of the NBC news website in mind.  I will need to create specific versions of this for each website since the layout of each news outlet's site is different.  \n",
    "\n",
    "    Args:\n",
    "        url_command (str): The URL of the news article.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (header_text, full_text, authors)\n",
    "            - header_text (str): The article's headline.\n",
    "            - full_text (str): The concatenated text of all paragraphs in the article body.\n",
    "            - authors (list): A list of authors' names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the HTML content\n",
    "        response = requests.get(url_command)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            return None, None, None\n",
    "\n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Extract header\n",
    "        header = soup.find(\"h1\", class_=\"article-hero-headline__htag lh-none-print black-print article-hero-headline__htag--live-breaking\")\n",
    "        header_text = header.text.strip() if header else \"Header not found\"\n",
    "\n",
    "        # Extract article body\n",
    "        article_body = soup.find(\"div\", class_=\"article-body__content\")\n",
    "        full_text = (\n",
    "            \" \".join(p.text.strip() for p in article_body.find_all(\"p\") if p.text.strip())\n",
    "            if article_body else \"Article body not found\"\n",
    "        )\n",
    "\n",
    "        # Extract authors\n",
    "        author_spans = soup.find_all(\"span\", class_=\"byline-name expanded-byline__name\")\n",
    "        authors = [span.text.strip() for span in author_spans] or [\"Authors not found\"]\n",
    "\n",
    "        return header_text, full_text, authors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None, None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.391841400Z",
     "start_time": "2025-01-13T17:58:46.371842500Z"
    }
   },
   "id": "780ca21f9911a0ae"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def extract_article_features_CNN(url_command):\n",
    "    \"\"\"\n",
    "    Extract the header, article body text, and authors from a news article.  Note this function has been created with the specifications of the NBC news website in mind.  I will need to create specific versions of this for each website since the layout of each news outlet's site is different.  \n",
    "\n",
    "    Args:\n",
    "        url_command (str): The URL of the news article.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (header_text, full_text, authors)\n",
    "            - header_text (str): The article's headline.\n",
    "            - full_text (str): The concatenated text of all paragraphs in the article body.\n",
    "            - authors (list): A list of authors' names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the HTML content\n",
    "        response = requests.get(url_command)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            return None, None, None\n",
    "\n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Extract header\n",
    "        header = soup.find(\"h1\", class_=\"headline__text inline-placeholder vossi-headline-text\")\n",
    "        header_text = header.text.strip() if header else \"Header not found\"\n",
    "        \n",
    "        \n",
    "        if header_text == \"Header not found\":\n",
    "            new_header = re.search(\"\")\n",
    "\n",
    "        # Extract article body\n",
    "        article_body = soup.find(\"div\", class_=\"article__content\")\n",
    "        full_text = (\n",
    "            \" \".join(p.text.strip() for p in article_body.find_all(\"p\") if p.text.strip())\n",
    "            if article_body else \"Article body not found\"\n",
    "        )\n",
    "\n",
    "        # Extract authors\n",
    "        author_spans = soup.find_all(\"span\", class_=\"byline__name\")\n",
    "        authors = [span.text.strip() for span in author_spans] or [\"Authors not found\"]\n",
    "\n",
    "        return header_text, full_text, authors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None, None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.458840100Z",
     "start_time": "2025-01-13T17:58:46.386842100Z"
    }
   },
   "id": "7c945ee44aa899ce"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def feature_extraction(article_df):\n",
    "    \"\"\"\n",
    "    Extracts article features (header, authors, full_text) based on the News_Source column.\n",
    "\n",
    "    Args:\n",
    "        article_df (pd.DataFrame): DataFrame containing columns 'URL' and 'News_Source'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with extracted features added as new columns.\n",
    "    \"\"\"\n",
    "    # Add new columns for the extracted features\n",
    "    article_df['header'] = np.nan\n",
    "    article_df['authors'] = np.nan\n",
    "    article_df['full_text'] = np.nan\n",
    "\n",
    "    for index, row in article_df.iterrows():\n",
    "        if row['News_Source'] == 'nbcnews':\n",
    "            try:\n",
    "                # Call the NBC-specific extraction function\n",
    "                header, full_text, authors = extract_article_features_NBC(row['URL'])\n",
    "                article_df.at[index, 'header'] = header\n",
    "                article_df.at[index, 'full_text'] = full_text\n",
    "                article_df.at[index, 'authors'] = \", \".join(authors) if authors else None\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL at index {index}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Add additional conditions for other news sources as needed\n",
    "        elif row['News_Source'] == 'cnn':\n",
    "            try:\n",
    "                # Call the NBC-specific extraction function\n",
    "                header, full_text, authors = extract_article_features_CNN(row['URL'])\n",
    "                article_df.at[index, 'header'] = header\n",
    "                article_df.at[index, 'full_text'] = full_text\n",
    "                article_df.at[index, 'authors'] = \", \".join(authors) if authors else None\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL at index {index}: {e}\")\n",
    "                continue\n",
    "            \n",
    "\n",
    "        # Handle unknown news sources\n",
    "        else:\n",
    "            print(f\"News source '{row['News_Source']}' not recognized. Skipping index {index}.\")\n",
    "\n",
    "    return article_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:46.475842800Z",
     "start_time": "2025-01-13T17:58:46.401843400Z"
    }
   },
   "id": "1ddb40ffa5a37ef7"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maggi\\AppData\\Local\\Temp\\ipykernel_21816\\3844325069.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Newsom says California wildfires will be one of the worst natural disasters in U.S. history' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  article_df.at[index, 'header'] = header\n",
      "C:\\Users\\maggi\\AppData\\Local\\Temp\\ipykernel_21816\\3844325069.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'California Gov. Gavin Newsom told NBC News’ “Meet the Press” Saturday that the Los Angeles-area wildfires will be one of the worst natural disasters in U.S. history and called for an independent investigation into the local water supply. “I think it will be in terms of just the costs associated with it, in terms of the scale and scope,” Newsom said when asked whether the disaster would be among the nation’s worst ever. His remarks came after firefighters said some fire hydrants ran dry in the first several hours as they were battling flames across greater Los Angeles on Wednesday. “Was it just overwhelm? That you had so much that was used, we drew it down? Was it pipes? Was it electricity? Was it a combination of pipes, electricities and pumps? Was that drawdown impossible because you lost seven-plus thousand structures right here anyway, and every single structure we lost had a pipe that was leaking, and we would’ve lost that water pressure anyway?” Newsom asked. “Did it contribute in any way to our inability to fight the fire? Or were 99 mile-an-hour winds determinative and there was really no firefight that could’ve been more meaningful?” he continued asking. On Wednesday, President-elect Donald Trump blamed Newsom and President Joe Biden for the lack of water in fire hydrants, writing on Truth Social, “NO WATER IN THE FIRE HYDRANTS, NO MONEY IN FEMA. THIS IS WHAT JOE BIDEN IS LEAVING ME. THANKS JOE!” The president-elect also criticized Newsom for not signing on to a plan that would have diverted water from Northern California to Southern California during Trump’s first term. Experts have said the debate has nothing to do with the current wildfires, which were caused by a long period without rain and heavy winds. Newsom “wanted to protect an essentially worthless fish called a smelt, by giving it less water (it didn’t work!), but didn’t care about the people of California,” the president-elect wrote in one Truth Social post. Trump is “somehow connecting the delta smelt to this fire, which is inexcusable because it’s inaccurate. Also, incomprehensible to anyone that understands water policy in the state,” Newsom said Saturday. He also blasted Trump for spreading other disinformation about the wildfires. The president-elect last week also attacked Los Angeles Mayor Karen Bass, a Democrat, writing on Truth Social that “Fire is spreading rapidly for 3 days — ZERO CONTAINMENT. Nobody has ever seen such failed numbers before! Gross incompetence by Gavin Newscum and Karen Bass.” On Saturday, Newsom said, “I have absolute faith in our community. I have faith in our leaders. I have the faith of our capacity to work together,” when asked whether he has faith in Bass, who was absent from Los Angeles when the wildfires broke out as she returned home from a trip to Ghana. Newsom also lauded Biden specifically, thanking him for issuing a major disaster declaration and allowing federal funds to flow to the state. “I’m blessed on behalf of 40 million Americans that happen to live in California that Joe Biden is president of the United States and did what he did immediately,” he said. “And to the extent that we can work with the same relationship and that same spirit with Donald Trump, I hope we can.” Newsom also spoke about his plans for rebuilding the city in the aftermath of the fires, speaking specifically about Los Angeles’ role in hosting the 2028 Olympic Games. “President of the United States, Donald Trump, to his credit, was helpful in getting the Olympics to the United States of America, to get it down here in L.A. We thank him for that. This is an opportunity for him to shine, for this country to shine, for California and this community to shine,” Newsom said. Ahead of the Olympics, Newsom added, “we’re already organizing a ‘Marshall Plan.’ We already have a team looking at reimagining L.A. 2.0, and we are making sure everyone’s included, not just the folks on the coast, people here that were ravaged by this disaster.” “We’re already talking to city leaders. We’re already talking to civic leaders. We’re already talking to business leaders, with nonprofits. We’re talking to labor leaders. We’re starting to organize how we can put together a collection of individuals on philanthropy for recovery. How we can organize the region,” Newsom said.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  article_df.at[index, 'full_text'] = full_text\n",
      "C:\\Users\\maggi\\AppData\\Local\\Temp\\ipykernel_21816\\3844325069.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Jacob Soboroff, Alexandra Marquez' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  article_df.at[index, 'authors'] = \", \".join(authors) if authors else None\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 URL News_Source  \\\n0  https://www.nbcnews.com/politics/politics-news...     nbcnews   \n1  https://www.nbcnews.com/news/world/magnitude-6...     nbcnews   \n2  https://www.nbcnews.com/news/world/north-korea...     nbcnews   \n3  https://www.nbcnews.com/news/world/taliban-not...     nbcnews   \n4  https://www.cnn.com/2025/01/13/middleeast/isra...         cnn   \n5  https://www.cnn.com/2025/01/13/politics/pete-h...         cnn   \n6  https://www.cnn.com/2025/01/11/middleeast/leba...         cnn   \n\n                                              header  \\\n0  Newsom says California wildfires will be one o...   \n1                                   Header not found   \n2                                   Header not found   \n3                                   Header not found   \n4  US officials say Gaza ceasefire deal is in sig...   \n5  Pete Hegseth says US military bases should res...   \n6  Watershed moment for the Middle East after Leb...   \n\n                                             authors  \\\n0                  Jacob Soboroff, Alexandra Marquez   \n1                                    Astha Rajvanshi   \n2     Stella Kim, Janis Mackey Frayer, Jennifer Jett   \n3                                    Astha Rajvanshi   \n4  Abeer Salman, Kareem Khadder, Mike Schwartz, L...   \n5                                   Andrew Kaczynski   \n6                                     Tamara Qiblawi   \n\n                                           full_text  \n0  California Gov. Gavin Newsom told NBC News’ “M...  \n1  A 6.6-magnitude earthquake has rattled the isl...  \n2  SEOUL, South Korea — About 300 North Korean tr...  \n3  Nobel Peace Prize laureate Malala Yousafzai de...  \n4  American officials believe a ceasefire and hos...  \n5  Pete Hegseth, President-elect Donald Trump’s p...  \n6  It was a last-minute push by Saudi Arabia that...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URL</th>\n      <th>News_Source</th>\n      <th>header</th>\n      <th>authors</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.nbcnews.com/politics/politics-news...</td>\n      <td>nbcnews</td>\n      <td>Newsom says California wildfires will be one o...</td>\n      <td>Jacob Soboroff, Alexandra Marquez</td>\n      <td>California Gov. Gavin Newsom told NBC News’ “M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.nbcnews.com/news/world/magnitude-6...</td>\n      <td>nbcnews</td>\n      <td>Header not found</td>\n      <td>Astha Rajvanshi</td>\n      <td>A 6.6-magnitude earthquake has rattled the isl...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.nbcnews.com/news/world/north-korea...</td>\n      <td>nbcnews</td>\n      <td>Header not found</td>\n      <td>Stella Kim, Janis Mackey Frayer, Jennifer Jett</td>\n      <td>SEOUL, South Korea — About 300 North Korean tr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.nbcnews.com/news/world/taliban-not...</td>\n      <td>nbcnews</td>\n      <td>Header not found</td>\n      <td>Astha Rajvanshi</td>\n      <td>Nobel Peace Prize laureate Malala Yousafzai de...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.cnn.com/2025/01/13/middleeast/isra...</td>\n      <td>cnn</td>\n      <td>US officials say Gaza ceasefire deal is in sig...</td>\n      <td>Abeer Salman, Kareem Khadder, Mike Schwartz, L...</td>\n      <td>American officials believe a ceasefire and hos...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://www.cnn.com/2025/01/13/politics/pete-h...</td>\n      <td>cnn</td>\n      <td>Pete Hegseth says US military bases should res...</td>\n      <td>Andrew Kaczynski</td>\n      <td>Pete Hegseth, President-elect Donald Trump’s p...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://www.cnn.com/2025/01/11/middleeast/leba...</td>\n      <td>cnn</td>\n      <td>Watershed moment for the Middle East after Leb...</td>\n      <td>Tamara Qiblawi</td>\n      <td>It was a last-minute push by Saudi Arabia that...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extraction(article_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:50.965800200Z",
     "start_time": "2025-01-13T17:58:46.415841400Z"
    }
   },
   "id": "4350eabae66dfe96"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "article_df.to_excel(\"Articles_With_Text.xlsx\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T17:58:51.040187400Z",
     "start_time": "2025-01-13T17:58:50.966802200Z"
    }
   },
   "id": "2630082077979e88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
